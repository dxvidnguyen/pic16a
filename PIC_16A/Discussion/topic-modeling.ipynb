{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion: Topic Modeling\n",
    "\n",
    "## Group Names and Roles\n",
    "\n",
    "- david (driver)\n",
    "- rashi (reviewer)\n",
    "- lauren(proposer)\n",
    "\n",
    "## Intro\n",
    "\n",
    "In this Discussion activity, we'll continue with with topic modeling. Recall that topic modeling can often be used to infer themes (or \"topics\") from sets of text data. Today, we will work through an example in which we download some data, prepare it appropriately, and deploy a topic model to obtain insights about the general themes present in the data. \n",
    "\n",
    "Our data set for this activity consists of the texts of a number of Associated Press articles. It was originally collected by David Blei. I retrieved this data set [here](https://github.com/tdhopper/topic-modeling-datasets/tree/master/data/lda-c/blei-ap). \n",
    "\n",
    "Run the following code chunk to create a large string `s` containing the entire data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "def retrieve_text(url):\n",
    "    \"\"\"\n",
    "    Retrieve text from the specified url and return \n",
    "    it as a string\n",
    "    \"\"\"\n",
    "    \n",
    "    # grab the data and parse it\n",
    "    filedata = urllib.request.urlopen(url) \n",
    "    data = filedata.read()\n",
    "    \n",
    "    return(data.decode())\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/PhilChodrow/PIC16A/master/datasets/blei-ap.txt'\n",
    "s = retrieve_text(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "Inspect `s`. Don't print out the entire string; just take a look at the first 5,000 characters or so. Write a function which, when `s` is provided as input, will return a list of document texts. It should exclude the excess tags and other metadata. Call this function to create a new list variable called `texts`, where each element of `texts` is the complete text of one news story. \n",
    "\n",
    "- ***Hint***: *First, split `s` on the newline character `\"\\n\"`. Then, return a list of elements of the result with length longer than 100. This can be done with a for-loop, but a conditional list comprehension will be more compact*\n",
    "\n",
    "The resulting list of news stories should have length 2226. \n",
    "\n",
    "Comments and docstrings are not necessary for this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFunction(s):\n",
    "    myString = s.split('\\n')\n",
    "    l = [i for i in myString if len(i) > 100]\n",
    "    return l \n",
    "\n",
    "\n",
    "texts = myFunction(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of the result\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Create a `pandas` data frame called `df` with a single column called `text`, whose rows are the entries of `texts`. This data frame should have 2226 rows. Show your data frame to check that it looks ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text' : texts\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 16-year-old student at a private Baptist sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A gunman took a 74-year-old woman hostage aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cupid has a new message for lovers this Valen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>The dollar rose in quiet European trading thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Here are the companies known to be conducting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Bloodstains on a pillowcase and exercise bar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>When Ron Thompson sat down for lunch on New Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>A Navy anti-submarine helicopter crashed whil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0      A 16-year-old student at a private Baptist sc...\n",
       "1      The Bechtel Group Inc. offered in 1985 to sel...\n",
       "2      A gunman took a 74-year-old woman hostage aft...\n",
       "3      Today is Saturday, Oct. 29, the 303rd day of ...\n",
       "4      Cupid has a new message for lovers this Valen...\n",
       "...                                                 ...\n",
       "2221   The dollar rose in quiet European trading thi...\n",
       "2222   Here are the companies known to be conducting...\n",
       "2223   Bloodstains on a pillowcase and exercise bar ...\n",
       "2224   When Ron Thompson sat down for lunch on New Y...\n",
       "2225   A Navy anti-submarine helicopter crashed whil...\n",
       "\n",
       "[2226 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "Create the term-document matrix. The group's **Reviewer** might want to check the [lecture notes](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/content/NLP/NLP_2.ipynb) on topic modeling for some code to do this. Add the term-document matrix to `df`. Make sure that the columns are labeled with the relevant word. \n",
    "\n",
    "I found that, for the purposes of the later parts of this exercise, the following arguments to `CountVectorizer` worked well: \n",
    "\n",
    "> `max_df = 100, min_df=0.01, stop_words='english'`\n",
    "\n",
    "However, please feel free to experiment. \n",
    "\n",
    "Call the new data frame with counts `big_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>00</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>110</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>130</th>\n",
       "      <th>150</th>\n",
       "      <th>152</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yard</th>\n",
       "      <th>yards</th>\n",
       "      <th>yen</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>yields</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 16-year-old student at a private Baptist sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A gunman took a 74-year-old woman hostage aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cupid has a new message for lovers this Valen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>The dollar rose in quiet European trading thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Here are the companies known to be conducting...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Bloodstains on a pillowcase and exercise bar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>When Ron Thompson sat down for lunch on New Y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>A Navy anti-submarine helicopter crashed whil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows Ã— 2542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  00  06  07  110  120  \\\n",
       "0      A 16-year-old student at a private Baptist sc...   0   0   0    0    0   \n",
       "1      The Bechtel Group Inc. offered in 1985 to sel...   0   0   0    0    0   \n",
       "2      A gunman took a 74-year-old woman hostage aft...   0   0   0    0    0   \n",
       "3      Today is Saturday, Oct. 29, the 303rd day of ...   0   0   0    0    0   \n",
       "4      Cupid has a new message for lovers this Valen...   0   0   0    0    0   \n",
       "...                                                 ...  ..  ..  ..  ...  ...   \n",
       "2221   The dollar rose in quiet European trading thi...   1   0   0    0    0   \n",
       "2222   Here are the companies known to be conducting...   0   0   0    0    0   \n",
       "2223   Bloodstains on a pillowcase and exercise bar ...   0   0   0    0    0   \n",
       "2224   When Ron Thompson sat down for lunch on New Y...   0   0   0    0    0   \n",
       "2225   A Navy anti-submarine helicopter crashed whil...   0   0   0    0    0   \n",
       "\n",
       "      125  130  150  152  ...  wrote  yard  yards  yen  yes  yield  yields  \\\n",
       "0       0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "1       0    0    0    0  ...      0     0      0    0    2      0       0   \n",
       "2       0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "3       0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "4       0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "...   ...  ...  ...  ...  ...    ...   ...    ...  ...  ...    ...     ...   \n",
       "2221    0    0    0    0  ...      0     0      0    5    0      0       0   \n",
       "2222    0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "2223    0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "2224    0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "2225    0    0    0    0  ...      0     0      0    0    0      0       0   \n",
       "\n",
       "      younger  youth  youths  \n",
       "0           0      1       0  \n",
       "1           0      0       0  \n",
       "2           0      0       0  \n",
       "3           0      0       0  \n",
       "4           0      0       0  \n",
       "...       ...    ...     ...  \n",
       "2221        0      0       0  \n",
       "2222        0      0       0  \n",
       "2223        0      0       0  \n",
       "2224        0      0       0  \n",
       "2225        0      0       0  \n",
       "\n",
       "[2226 rows x 2542 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(max_df = 100, min_df=0.01, stop_words='english')\n",
    "counts = vec.fit_transform(df['text'])\n",
    "counts = counts.toarray()\n",
    "big_df = pd.DataFrame(counts, columns = vec.get_feature_names())\n",
    "big_df = pd.concat((df, big_df), axis = 1)\n",
    "big_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D\n",
    "\n",
    "Create an input matrix `X` which is identical to `big_df` but drops the `text` column. Then, create a Nonnegative Matrix Factorization (NMF) model and fit it to `X`. Start with 10 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = big_df.drop([\\'text\\'], axis = 1)\\nmodel = NMF(n_components = 10, init = \"random\", random_state = 0)\\nmodel.fit(X)\\n\\n\\norders = np.argsort(model.components_, axis = 1)\\n\\n\\n\\nimportant_words = np.array(X.columns)[orders]\\n\\n\\nweights = model.transform(X)\\n\\nfig, ax = plt.subplots(1)\\n\\nax.imshow(weights.T)\\n\\n\\n#model.components_.shape\\norders\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "X = big_df.drop(['text'], axis = 1 )\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "\n",
    "'''\n",
    "X = big_df.drop(['text'], axis = 1)\n",
    "model = NMF(n_components = 10, init = \"random\", random_state = 0)\n",
    "model.fit(X)\n",
    "orders = np.argsort(model.components_, axis = 1)\n",
    "important_words = np.array(X.columns)[orders]\n",
    "weights = model.transform(X)\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(weights.T)\n",
    "\n",
    "\n",
    "#model.components_.shape\n",
    "orders\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E\n",
    "\n",
    "The following code (from lecture) will extract the top words within each topic. Run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def top_words(X, model, component, num_words):\n",
    "    \"\"\"\n",
    "    Extract the top words from the specified component \n",
    "    for a topic model trained on data. \n",
    "    X: a term-document matrix, assumed to be a pd.DataFrame\n",
    "    model: a sklearn model with a components_ attribute, e.g. NMF\n",
    "    component: the desired component, specified as an integer. \n",
    "        Must be less than than the total number of components in model\n",
    "    num_words: the number of words to return.\n",
    "    \"\"\"\n",
    "    orders = np.argsort(model.components_, axis = 1)\n",
    "    important_words = np.array(X.columns)[orders]\n",
    "    return important_words[component][-num_words:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code to investigate the topics constructed by the model. Can you interpret any of them? Keep in mind that many of these news articles are from the 1980s and 1990s. That's before many of you were born, you whippersnappers! \n",
    "\n",
    "I was able to find U.S. political party conventions; fluctuations in the price of oil; U.S. / Soviet tensions; and international finance news, among other things. Show the top words for a few different topics, and see whether any of them look interpretable to you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top words for a topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top words for a topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top words for a topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the top words for a topic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
